{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bdh777psu/UCSD-MLE_Bootcamp_Projects/blob/main/Customer_Churn_Modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mini-Project: An End-to-End Churn Prediction Model Using AWS\n",
        "\n",
        "Churn prediction is a crucial aspect for businesses, especially those operating in subscription-based models or industries with high customer turnover. Churn refers to the phenomenon where customers discontinue using a product or service. Predicting churn is important for several reasons:\n",
        "\n",
        "1. **Revenue Impact:**\n",
        "   - Retaining existing customers is often more cost-effective than acquiring new ones. Losing customers means losing the associated revenue. Churn prediction helps businesses identify customers at risk of leaving so that proactive measures can be taken to retain them.\n",
        "\n",
        "2. **Resource Allocation:**\n",
        "   - By predicting which customers are likely to churn, businesses can allocate resources more efficiently. They can concentrate efforts and resources on retaining high-value customers who are at a higher risk of leaving, rather than applying blanket retention strategies.\n",
        "\n",
        "3. **Customer Experience Improvement:**\n",
        "   - Understanding why customers churn provides valuable insights into areas that may need improvement. It could be issues related to product quality, customer service, or competitive factors. Identifying and addressing these issues can enhance overall customer experience.\n",
        "\n",
        "In this mini-project, you'll be building an end-to-end churn prediction model using AWS's SageMaker. Amazon SageMaker is a fully managed service that simplifies the process of building, training, and deploying machine learning models at scale. It's designed to make it easier for developers to build, train, and deploy machine learning models in a production environment. Click [here](https://aws.amazon.com/blogs/machine-learning/build-tune-and-deploy-an-end-to-end-churn-prediction-model-using-amazon-sagemaker-pipelines/) and follow the instructions to build an end-to-end churn prediction model using AWS.   "
      ],
      "metadata": {
        "id": "k9fDfOu759G_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuAM83SW3rel"
      },
      "source": [
        "## Customer Churn Model Using XGBoost Framework"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqavOFMu3rem"
      },
      "source": [
        "### 1. Customer Retention Retail Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h92ibSL43ren"
      },
      "source": [
        "This dataset can be used to understand what are the various marketing strategy based on consumer behaviour that can be adopted to increase customer retention of a retail store.\n",
        "\n",
        "An online tea retail store which sells tea of different flavors across various cities in India. The dataset contains data about the store's customers, their orders, quantity ordered, order frequency, city,etc. This is a large dataset which will help in analysis.\n",
        "\n",
        "Reference: https://www.kaggle.com/uttamp/store-data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "Shy842Wz3ren",
        "outputId": "a4a7b781-fef9-46e2-a65d-f7629d640702",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "table {float:left}\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "%%html\n",
        "<style>\n",
        "table {float:left}\n",
        "</style>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MESifEks3reo"
      },
      "source": [
        "| column | Description\n",
        "|--|--|\n",
        "| custid | Computer generated ID to identify customers throughout the database\n",
        "|retained |\t1, if customer is assumed to be active, 0 = otherwise\n",
        "|created | Date when the contact was created in the database - when the customer joined\n",
        "|firstorder | Date when the customer placed first order\n",
        "|lastorder | Date when the customer placed last order\n",
        "|esent |\tNumber of emails sent\n",
        "|eopenrate | Number of emails opened divided by number of emails sent\n",
        "|eclickrate | Number of emails clicked divided by number of emails sent\n",
        "|avgorder | Average order size for the customer\n",
        "|ordfreq | Number of orders divided by customer tenure\n",
        "|paperless | 1 if customer subscribed for paperless communication (only online)\n",
        "|refill | 1 if customer subscribed for automatic refill\n",
        "|doorstep | 1 if customer subscribed for doorstep delivery\n",
        "|train | 1 if customer is in the training database\n",
        "|favday | Customer's favorite delivery day\n",
        "|city | City where the customer resides in"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsQBMIqJ3reo"
      },
      "source": [
        "### 2. Import Packages and Constants"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcC25aW53reo"
      },
      "source": [
        "Install shap and smdebug packages if not already installed and restart kernel after installing the packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_QFHO4sC3reo",
        "outputId": "cfff395b-ede0-4269-f691-9d1e89c9ea19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: conda: command not found\n",
            "Collecting smdebug\n",
            "  Downloading smdebug-1.0.34-py2.py3-none-any.whl (280 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.1/280.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf<=3.20.3,>=3.20.0 in /usr/local/lib/python3.10/dist-packages (from smdebug) (3.20.3)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from smdebug) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from smdebug) (24.0)\n",
            "Collecting boto3>=1.10.32 (from smdebug)\n",
            "  Downloading boto3-1.34.82-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyinstrument==3.4.2 (from smdebug)\n",
            "  Downloading pyinstrument-3.4.2-py2.py3-none-any.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.3/83.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyinstrument-cext>=0.2.2 (from pyinstrument==3.4.2->smdebug)\n",
            "  Downloading pyinstrument_cext-0.2.4.tar.gz (4.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting botocore<1.35.0,>=1.34.82 (from boto3>=1.10.32->smdebug)\n",
            "  Downloading botocore-1.34.82-py3-none-any.whl (12.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.10.32->smdebug)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3>=1.10.32->smdebug)\n",
            "  Downloading s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.82->boto3>=1.10.32->smdebug) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.82->boto3>=1.10.32->smdebug) (2.0.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.82->boto3>=1.10.32->smdebug) (1.16.0)\n",
            "Building wheels for collected packages: pyinstrument-cext\n",
            "  Building wheel for pyinstrument-cext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyinstrument-cext: filename=pyinstrument_cext-0.2.4-cp310-cp310-linux_x86_64.whl size=14873 sha256=8aa7b465460fefd3a544cf0278b117be012f3db94943e16527ed93bef305a0ff\n",
            "  Stored in directory: /root/.cache/pip/wheels/0f/8b/7a/5f7fd1dd6d3cbb3d350d4c832c5e2f962687749f6d67d573a6\n",
            "Successfully built pyinstrument-cext\n",
            "Installing collected packages: pyinstrument-cext, pyinstrument, jmespath, botocore, s3transfer, boto3, smdebug\n",
            "Successfully installed boto3-1.34.82 botocore-1.34.82 jmespath-1.0.1 pyinstrument-3.4.2 pyinstrument-cext-0.2.4 s3transfer-0.10.1 smdebug-1.0.34\n"
          ]
        }
      ],
      "source": [
        "!conda install -c conda-forge shap --yes\n",
        "!pip install smdebug --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Q0XGLyea3reo",
        "outputId": "ff4751c3-eb3b-4c62-a253-cc47deb1ba7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 's3fs'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-74a0b691d50e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0ms3fs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mboto3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 's3fs'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import re\n",
        "import s3fs\n",
        "import shap\n",
        "import time\n",
        "import boto3\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from itertools import islice\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sagemaker\n",
        "from sagemaker.xgboost.estimator import XGBoost\n",
        "from sagemaker.session import Session\n",
        "from sagemaker.inputs import TrainingInput\n",
        "from sagemaker.debugger import DebuggerHookConfig,CollectionConfig\n",
        "from sagemaker.debugger import rule_configs, Rule\n",
        "from smdebug.trials import create_trial\n",
        "from sagemaker.tuner import (\n",
        "    IntegerParameter,\n",
        "    CategoricalParameter,\n",
        "    ContinuousParameter,\n",
        "    HyperparameterTuner\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1NAKzmF3reo"
      },
      "outputs": [],
      "source": [
        "#Replace this value with the S3 Bucket Created\n",
        "\n",
        "default_bucket = \"customer-churn-sm-pipeline\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sv1SK6pF3rep"
      },
      "outputs": [],
      "source": [
        "sagemaker_session = sagemaker.Session()\n",
        "role = sagemaker.get_execution_role()\n",
        "region = sagemaker_session.boto_region_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVJhRQLv3rep"
      },
      "source": [
        "### 3. Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evnia7gk3rep"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    ## Convert to datetime columns\n",
        "    df[\"firstorder\"]=pd.to_datetime(df[\"firstorder\"],errors='coerce')\n",
        "    df[\"lastorder\"] = pd.to_datetime(df[\"lastorder\"],errors='coerce')\n",
        "    ## Drop Rows with null values\n",
        "    df = df.dropna()\n",
        "    ## Create Column which gives the days between the last order and the first order\n",
        "    df[\"first_last_days_diff\"] = (df['lastorder']-df['firstorder']).dt.days\n",
        "    ## Create Column which gives the days between when the customer record was created and the first order\n",
        "    df['created'] = pd.to_datetime(df['created'])\n",
        "    df['created_first_days_diff']=(df['created']-df['firstorder']).dt.days\n",
        "    ## Drop Columns\n",
        "    df.drop(['custid','created','firstorder','lastorder'],axis=1,inplace=True)\n",
        "    ## Apply one hot encoding on favday and city columns\n",
        "    df = pd.get_dummies(df,prefix=['favday','city'],columns=['favday','city'])\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5WBuvc43rep"
      },
      "outputs": [],
      "source": [
        "storedata = preprocess_data(f\"s3://{default_bucket}/data/storedata_total.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8bpAueS3rep"
      },
      "outputs": [],
      "source": [
        "storedata.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RlnSmyd3rep"
      },
      "source": [
        "### 4. Split Train, Test and Validation Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TssQSbld3rep"
      },
      "outputs": [],
      "source": [
        "def split_datasets(df):\n",
        "    y=df.pop(\"retained\")\n",
        "    X_pre = df\n",
        "    y_pre = y.to_numpy().reshape(len(y),1)\n",
        "    feature_names = list(X_pre.columns)\n",
        "    X= np.concatenate((y_pre,X_pre),axis=1)\n",
        "    np.random.shuffle(X)\n",
        "    train,validation,test=np.split(X,[int(.7*len(X)),int(.85*len(X))])\n",
        "    return feature_names,train,validation,test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PREK2Iqq3rep"
      },
      "outputs": [],
      "source": [
        "feature_names,train,validation,test = split_datasets(storedata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkHeV4ho3rep"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(train).to_csv(f\"s3://{default_bucket}/data/train/train.csv\",header=False,index=False)\n",
        "pd.DataFrame(validation).to_csv(f\"s3://{default_bucket}/data/validation/validation.csv\",header=False,index=False)\n",
        "pd.DataFrame(test).to_csv(f\"s3://{default_bucket}/data/test/test.csv\",header=False,index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vo2gJv7t3rep"
      },
      "source": [
        "### 5. Hyperparameter Tuning HPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmwhVWOh3rep"
      },
      "outputs": [],
      "source": [
        "s3_input_train = TrainingInput(\n",
        "    s3_data=f\"s3://{default_bucket}/data/train/\",content_type=\"csv\")\n",
        "s3_input_validation = TrainingInput(\n",
        "    s3_data=f\"s3://{default_bucket}/data/validation/\",content_type=\"csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cD6LWE_z3rep"
      },
      "outputs": [],
      "source": [
        "fixed_hyperparameters = {\n",
        "    \"eval_metric\":\"auc\",\n",
        "    \"objective\":\"binary:logistic\",\n",
        "    \"num_round\":\"100\",\n",
        "    \"rate_drop\":\"0.3\",\n",
        "    \"tweedie_variance_power\":\"1.4\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEiTGK0O3req"
      },
      "outputs": [],
      "source": [
        "sess = sagemaker.Session()\n",
        "container = sagemaker.image_uris.retrieve(\"xgboost\",region,\"0.90-2\")\n",
        "\n",
        "estimator = sagemaker.estimator.Estimator(\n",
        "    container,\n",
        "    role,\n",
        "    instance_count=1,\n",
        "    hyperparameters=fixed_hyperparameters,\n",
        "    instance_type=\"ml.m4.xlarge\",\n",
        "    output_path=\"s3://{}/output\".format(default_bucket),\n",
        "    sagemaker_session=sagemaker_session\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mw1ldVce3req"
      },
      "outputs": [],
      "source": [
        "hyperparameter_ranges = {\n",
        "    \"eta\": ContinuousParameter(0, 1),\n",
        "    \"min_child_weight\": ContinuousParameter(1, 10),\n",
        "    \"alpha\": ContinuousParameter(0, 2),\n",
        "    \"max_depth\": IntegerParameter(1, 10),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-gvSWXt3req"
      },
      "outputs": [],
      "source": [
        "objective_metric_name = \"validation:auc\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BK3zkpRm3req"
      },
      "outputs": [],
      "source": [
        "tuner = HyperparameterTuner(\n",
        "    estimator,objective_metric_name,hyperparameter_ranges,max_jobs=10,max_parallel_jobs=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LiU4qaBL3req"
      },
      "outputs": [],
      "source": [
        "tuner.fit({\n",
        "    \"train\":s3_input_train,\n",
        "    \"validation\":s3_input_validation\n",
        "    },include_cls_metadata=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzKHWgmz3req"
      },
      "outputs": [],
      "source": [
        "tuning_job_result = boto3.client(\"sagemaker\").describe_hyper_parameter_tuning_job(\n",
        "    HyperParameterTuningJobName=tuner.latest_tuning_job.job_name\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SIV2Wd53req"
      },
      "outputs": [],
      "source": [
        "job_count = tuning_job_result[\"TrainingJobStatusCounters\"][\"Completed\"]\n",
        "print(\"%d training jobs have completed\" %job_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPP5Fmtd3req"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "\n",
        "if tuning_job_result.get(\"BestTrainingJob\",None):\n",
        "    print(\"Best Model found so far:\")\n",
        "    pprint(tuning_job_result[\"BestTrainingJob\"])\n",
        "else:\n",
        "    print(\"No training jobs have reported results yet.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6rQrxWI3req"
      },
      "outputs": [],
      "source": [
        "best_hyperparameters = tuning_job_result[\"BestTrainingJob\"][\"TunedHyperParameters\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CqqrnOuX3req"
      },
      "outputs": [],
      "source": [
        "best_hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_aShEEi3req"
      },
      "source": [
        "### 7. XGBoost Model with SageMaker Debugger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgG2e8GB3req"
      },
      "outputs": [],
      "source": [
        "hyperparameters = {**fixed_hyperparameters,**best_hyperparameters}\n",
        "save_interval = 5\n",
        "base_job_name = \"demo-smdebug-xgboost-churn-classification\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMsDHHsZ3req"
      },
      "outputs": [],
      "source": [
        "container = sagemaker.image_uris.retrieve(\"xgboost\",region,\"0.90-2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lM4Bts_3req"
      },
      "outputs": [],
      "source": [
        "estimator = sagemaker.estimator.Estimator(\n",
        "    container,\n",
        "    role,\n",
        "    base_job_name=base_job_name,\n",
        "    instance_count=1,\n",
        "    instance_type=\"ml.m4.xlarge\",\n",
        "    output_path=\"s3://{}/output\".format(default_bucket),\n",
        "    sagemaker_session=sess,\n",
        "    hyperparameters=hyperparameters,\n",
        "    max_run=1800,\n",
        "    debugger_hook_config = DebuggerHookConfig(\n",
        "        s3_output_path=f\"s3://{default_bucket}/debugger/\",  # Required\n",
        "        collection_configs=[\n",
        "            CollectionConfig(\n",
        "                name=\"metrics\",\n",
        "                parameters={\n",
        "                    \"save_interval\": \"5\"\n",
        "                }),\n",
        "            CollectionConfig(\n",
        "                name=\"feature_importance\", parameters={\"save_interval\": \"5\"}\n",
        "            ),\n",
        "            CollectionConfig(name=\"full_shap\", parameters={\"save_interval\": \"5\"}),\n",
        "            CollectionConfig(name=\"average_shap\", parameters={\"save_interval\": \"5\"}),\n",
        "        ]\n",
        "    ),\n",
        "    rules=[\n",
        "        Rule.sagemaker(\n",
        "            rule_configs.loss_not_decreasing(),\n",
        "            rule_parameters={\n",
        "                \"collection_names\": \"metrics\",\n",
        "                \"num_steps\": \"10\",\n",
        "            },\n",
        "        ),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xBeO2kY3rer"
      },
      "outputs": [],
      "source": [
        "estimator.fit(\n",
        "        {\"train\":s3_input_train,\"validation\":s3_input_validation},wait=False\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65LvQvbK3rer"
      },
      "outputs": [],
      "source": [
        "for _ in range(36):\n",
        "    job_name = estimator.latest_training_job.name\n",
        "    client = estimator.sagemaker_session.sagemaker_client\n",
        "    description = client.describe_training_job(TrainingJobName=job_name)\n",
        "    training_job_status = description[\"TrainingJobStatus\"]\n",
        "    rule_job_summary = estimator.latest_training_job.rule_job_summary()\n",
        "    rule_evaluation_status = rule_job_summary[0][\"RuleEvaluationStatus\"]\n",
        "    print(\n",
        "        \"Training job status: {}, Rule Evaluation Status: {}\".format(\n",
        "            training_job_status, rule_evaluation_status\n",
        "        )\n",
        "    )\n",
        "    if training_job_status in [\"Completed\", \"Failed\"]:\n",
        "        break\n",
        "    time.sleep(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpjuJHT73rer"
      },
      "source": [
        "### 8. Analyze Debugger Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQ6CIcr43rew"
      },
      "outputs": [],
      "source": [
        "estimator.latest_training_job.rule_job_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3K4FEMd3rew"
      },
      "outputs": [],
      "source": [
        "s3_output_path = estimator.latest_job_debugger_artifacts_path()\n",
        "trial = create_trial(s3_output_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ImOlp8Y3rew"
      },
      "outputs": [],
      "source": [
        "trial.tensor_names()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ll4I3ve3rew"
      },
      "outputs": [],
      "source": [
        "trial.tensor(\"average_shap/f1\").values()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14kpoSGK3rew"
      },
      "outputs": [],
      "source": [
        "MAX_PLOTS = 35\n",
        "\n",
        "\n",
        "def get_data(trial, tname):\n",
        "    \"\"\"\n",
        "    For the given tensor name, walks though all the iterations\n",
        "    for which you have data and fetches the values.\n",
        "    Returns the set of steps and the values.\n",
        "    \"\"\"\n",
        "    tensor = trial.tensor(tname)\n",
        "    steps = tensor.steps()\n",
        "    vals = [tensor.value(s) for s in steps]\n",
        "    return steps, vals\n",
        "\n",
        "\n",
        "def match_tensor_name_with_feature_name(tensor_name, feature_names=feature_names):\n",
        "    feature_tag = tensor_name.split(\"/\")\n",
        "    for ifeat, feature_name in enumerate(feature_names):\n",
        "        if feature_tag[-1] == \"f{}\".format(str(ifeat)):\n",
        "            return feature_name\n",
        "    return tensor_name\n",
        "\n",
        "\n",
        "def plot_collection(trial, collection_name, regex=\".*\", figsize=(8, 6)):\n",
        "    \"\"\"\n",
        "    Takes a `trial` and a collection name, and\n",
        "    plots all tensors that match the given regex.\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "    tensors = trial.collection(collection_name).tensor_names\n",
        "    matched_tensors = [t for t in tensors if re.match(regex, t)]\n",
        "    for tensor_name in islice(matched_tensors, MAX_PLOTS):\n",
        "        steps, data = get_data(trial, tensor_name)\n",
        "        ax.plot(steps, data, label=match_tensor_name_with_feature_name(tensor_name))\n",
        "\n",
        "    ax.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
        "    ax.set_xlabel(\"Iteration\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXpclPef3rew"
      },
      "outputs": [],
      "source": [
        "plot_collection(trial, \"metrics\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_E8DIaMg3rew"
      },
      "outputs": [],
      "source": [
        "def plot_feature_importance(trial, importance_type=\"weight\"):\n",
        "    SUPPORTED_IMPORTANCE_TYPES = [\"weight\", \"gain\", \"cover\", \"total_gain\", \"total_cover\"]\n",
        "    if importance_type not in SUPPORTED_IMPORTANCE_TYPES:\n",
        "        raise ValueError(f\"{importance_type} is not one of the supported importance types.\")\n",
        "    plot_collection(trial, \"feature_importance\", regex=f\"feature_importance/{importance_type}/.*\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMYqRzcm3rew"
      },
      "outputs": [],
      "source": [
        "plot_feature_importance(trial, importance_type=\"cover\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BX7w6kww3rew"
      },
      "source": [
        "### SHAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7Pbmdrs3rew"
      },
      "outputs": [],
      "source": [
        "plot_collection(trial, \"average_shap\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58xSrI-p3rex"
      },
      "source": [
        "### Global Explanations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjtxBF8S3rex"
      },
      "outputs": [],
      "source": [
        "shap_values = trial.tensor(\"full_shap/f0\").value(trial.last_complete_step)\n",
        "shap_no_base = shap_values[:, :-1]\n",
        "shap_base_value = shap_values[0, -1]\n",
        "shap.summary_plot(shap_no_base, plot_type=\"bar\", feature_names=feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZQPOG5N3rex"
      },
      "outputs": [],
      "source": [
        "shap_base_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vU-XDSkf3rex"
      },
      "outputs": [],
      "source": [
        "train_shap = pd.DataFrame(train[:,1:],columns=feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPxYpyJf3rex"
      },
      "outputs": [],
      "source": [
        "shap.summary_plot(shap_no_base, train_shap)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0H5Sxc_3rex"
      },
      "source": [
        "### Local Explanations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5cTOIy53rex"
      },
      "outputs": [],
      "source": [
        "shap.initjs()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3cy-dda3rex"
      },
      "outputs": [],
      "source": [
        "shap.force_plot(\n",
        "    shap_base_value,\n",
        "    shap_no_base[100, :],\n",
        "    train_shap.iloc[100, :],\n",
        "    link=\"logit\",\n",
        "    matplotlib=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ALEZGNi3rex"
      },
      "outputs": [],
      "source": [
        "N_ROWS = shap_no_base.shape[0]\n",
        "N_SAMPLES = min(100, N_ROWS)\n",
        "sampled_indices = np.random.randint(N_ROWS, size=N_SAMPLES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZg41PXp3rex"
      },
      "outputs": [],
      "source": [
        "shap.force_plot(\n",
        "    shap_base_value,\n",
        "    shap_no_base[sampled_indices, :],\n",
        "    train_shap.iloc[sampled_indices, :],\n",
        "    link=\"logit\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tn1OeV173rex"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "instance_type": "ml.t3.medium",
    "kernelspec": {
      "display_name": "Python 3 (Data Science)",
      "language": "python",
      "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}